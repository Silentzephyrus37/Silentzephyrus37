<img align="right" width="200" src="octocat.gif" alt="Octocat detective" />

Hi, Iâ€™m Samuel. Iâ€™m a Security Researcher driven by a simple question: Why does security so often feel like itâ€™s fighting the user? I believe that the strongest defenses are those that protect people without getting in their way, turning security into a seamless asset rather than a technical hurdle.I am currently focused on the intersection of AI and LLM security, specifically identifying vulnerabilities in agentic workflows and adversarial prompt engineering. My goal is to engineer robust, invisible guardrails that secure autonomous systems while preserving the intuitive experience that users expect.

<br clear="right"/>

## ğŸ“° Reading List

Things I've read and kept thinking about. Updated when something actually sticks.

**01 Â· [Indirect Prompt Injection Attacks Against LLM-Integrated Applications](https://arxiv.org/abs/2302.12173)**
`Greshake et al. Â· 2023` &nbsp; `Prompt Injection` &nbsp; `Agentic Security`
The paper that made me realize how wide the attack surface actually is once you start chaining LLM calls. Required reading before building anything agentic.

**02 Â· [MITRE ATLAS: Adversarial Threat Landscape for AI Systems](https://atlas.mitre.org/)**
`MITRE Â· Ongoing` &nbsp; `AI Red Teaming` &nbsp; `Threat Modeling`
ATT&CK for ML systems. I go back to this constantly when thinking through what a detection pipeline should actually be watching for.

**03 Â· [Zero Trust Architecture â€” NIST SP 800-207](https://csrc.nist.gov/publications/detail/sp/800-207/final)**
`NIST Â· 2020` &nbsp; `Zero Trust` &nbsp; `Architecture`
Takes some effort to get through but worth it. A lot of how I think about authentication and trust scoring traces back to the principles in here.

**04 Â· [SoK: Attacks on Large Language Models](https://arxiv.org/abs/2402.06674)**
`Yao et al. Â· 2024` &nbsp; `LLM Security` &nbsp; `Survey`
The most complete map of the LLM attack landscape I've come across. Good place to start if you're trying to understand the threat surface before jumping into red teaming.

---

![GitHub Space Shooter](game.gif)


---

<!-- SECURITY-START -->
## ğŸ›°ï¸ Threat Intelligence
<p align="center"><i>Refresh: Daily â€¢ 2026-02-20 12:50 UTC</i></p>

| Threat Analysis | Recent Breaches |
| :---: | :---: |
| [`CVE-1999-0095`](https://nvd.nist.gov/vuln/detail/CVE-1999-0095) &nbsp; **10.0** &nbsp; ğŸ”´ `CRIT` <br> Sendmail debug command is enabled, allowing root command execution. | [**CarMax**](https://carmax.com) â€¢ 431,371 <br> `email` `names` `phone` |
| [`CVE-1999-0082`](https://nvd.nist.gov/vuln/detail/CVE-1999-0082) &nbsp; **10.0** &nbsp; ğŸ”´ `CRIT` <br> CWD ~root command in ftpd allows direct root access. | [**Figure**](https://figure.com) â€¢ 967,178 <br> `dob` `email` `names` |
| [`CVE-1999-1471`](https://nvd.nist.gov/vuln/detail/CVE-1999-1471) &nbsp; **7.2** &nbsp; ğŸŸ¡ `MED` <br> Buffer overflow in passwd allows local users to gain root privileges. | [**Canada Goose**](https://canadagoose.com) â€¢ 581,877 <br> `device` `ip` `email` |
<!-- SECURITY-END -->
---


